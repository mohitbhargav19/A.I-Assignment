{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a26a44cd-997e-4a99-a50f-3195173f10b9",
   "metadata": {},
   "source": [
    "# README ----\n",
    "\n",
    "Aave V2 Wallet Credit Scoring Model\n",
    "This project develops a machine learning model to assign a credit score (0-1000) to Aave V2 wallets based on their historical transaction behavior. The score aims to reflect a wallet's reliability and responsible usage, with higher scores indicating better behavior and lower scores indicating riskier or potentially exploitative patterns.\n",
    "\n",
    "Challenge Overview\n",
    "The task was to analyze raw, transaction-level data from the Aave V2 protocol, specifically focusing on actions like deposit, borrow, repay, redeemUnderlying, and liquidationCall. Based on this data, a robust machine learning model was developed to assign a credit score to each unique wallet.\n",
    "\n",
    "Data Source\n",
    "The model is trained and operates on a sample of user-transactions provided as a JSON file (~87MB). This file contains transaction-level details including wallet, action, value, and timestamp.\n",
    "\n",
    "Feature Engineering Strategy\n",
    "From the raw transaction data, the following features were engineered to capture various aspects of a wallet's interaction with the Aave V2 protocol. These features are designed to proxy creditworthiness:\n",
    "\n",
    "deposit_count / total_value_deposited: Number and total value of assets deposited. Indicates participation and capital provided.\n",
    "\n",
    "borrow_count / total_value_borrowed: Number and total value of assets borrowed. Indicates reliance on protocol's lending.\n",
    "\n",
    "repay_count / total_value_repaid: Number and total value of repaid loans. Crucial for creditworthiness.\n",
    "\n",
    "redeem_count / total_value_redeemed: Number and total value of redeemed collateral. Frequent redemptions might suggest short-term engagement.\n",
    "\n",
    "liquidation_count / total_value_liquidated: Number and total value of liquidations incurred by the wallet. A strong negative indicator, reflecting failure to maintain collateral.\n",
    "\n",
    "account_age_days: Duration between the first and last transaction. Longer activity periods might imply stability.\n",
    "\n",
    "borrow_repay_ratio: total_value_repaid / total_value_borrowed. A ratio significantly greater than 1 suggests over-repayment or consistent good behavior. A ratio near 0 or less indicates unrepaid debt.\n",
    "\n",
    "net_borrow_exposure: total_value_borrowed - total_value_repaid. Represents the outstanding borrowed amount. Higher values are riskier.\n",
    "\n",
    "liquidation_rate: liquidation_count / total_transactions. Frequency of liquidations relative to total activity.\n",
    "\n",
    "Score Logic and Interpretation (0-1000)\n",
    "Since explicit credit scores were not provided, a heuristic target score was defined to train the supervised learning model. This heuristic assigns a score between 0 and 1000 based on predefined rules that reflect 'good' vs. 'bad' DeFi behavior:\n",
    "\n",
    "Higher Scores (e.g., 700-1000): Indicative of wallets that consistently repay their loans, have a low (ideally zero) number of liquidations, show substantial value repaid, and demonstrate sustained activity on the platform. These wallets represent reliable and responsible usage.\n",
    "\n",
    "Mid Scores (e.g., 400-699): May represent wallets with mixed activity, occasional borrowing and repayment, but perhaps some unrepaid exposure or limited history.\n",
    "\n",
    "Lower Scores (e.g., 0-399): Reflect wallets that have experienced liquidations, have a significant net_borrow_exposure, or exhibit patterns suggestive of risky, bot-like, or exploitative behavior (e.g., many small, rapid transactions that could be part of an exploit, although further analysis would be needed to confirm 'bot-like' specifically).\n",
    "\n",
    "The Gradient Boosting Regressor then learns to map the engineered features to this heuristic score.\n",
    "\n",
    "Model Architecture\n",
    "A Gradient Boosting Regressor from scikit-learn was chosen for this task.\n",
    "\n",
    "Reasoning: Gradient Boosting models are powerful, robust to various data types, capable of capturing non-linear relationships, and provide insights into feature importance, which aids in explaining the score logic.\n",
    "\n",
    "Preprocessing: Features are scaled using StandardScaler to ensure all features contribute equally to the model, regardless of their original magnitude.\n",
    "\n",
    "How to Set Up and Run the Code\n",
    "Download the Data:\n",
    "Download the user-transactions.json file from:\n",
    "https://drive.google.com/file/d/1ISFbAXxadMrt7Zl96rmzzZmEKZnyW7FS/view?usp=sharing\n",
    "Place this file in the root directory of your project.\n",
    "\n",
    "Clone the Repository:\n",
    "\n",
    "git clone https://github.com/your-username/your-repo-name.git\n",
    "cd your-repo-name\n",
    "\n",
    "Create and Activate Virtual Environment:\n",
    "\n",
    "python -m venv venv\n",
    "# On Windows:\n",
    ".\\venv\\Scripts\\activate\n",
    "# On macOS/Linux:\n",
    "source venv/bin/activate\n",
    "\n",
    "Install Dependencies:\n",
    "\n",
    "pip install pandas numpy scikit-learn\n",
    "\n",
    "Run the Jupyter Notebook:\n",
    "\n",
    "jupyter lab\n",
    "\n",
    "Open the aave_credit_score.ipynb notebook and run all cells sequentially. This will:\n",
    "\n",
    "Load the data.\n",
    "\n",
    "Engineer features.\n",
    "\n",
    "Define and assign heuristic scores.\n",
    "\n",
    "Train the ML model and save model.joblib and scaler.joblib.\n",
    "\n",
    "Demonstrate the \"one-step\" scoring process by loading the saved model and generating scores, saving them to wallet_credit_scores_generated.json.\n",
    "\n",
    "Output:\n",
    "The final wallet credit scores will be saved in wallet_credit_scores_generated.json in the same directory.\n",
    "\n",
    "Extensibility and Future Improvements\n",
    "Advanced Feature Engineering: Incorporate time-series analysis (e.g., moving averages of debt, repayment streaks), asset-specific features (volatility of collateral assets), and network graph analysis (interactions between wallets).\n",
    "\n",
    "External Data Integration: Leverage external DeFi data sources (e.g., oracle prices, total value locked, token liquidity) for richer context.\n",
    "\n",
    "Dynamic Target Definition: Develop a more sophisticated, potentially unsupervised or semi-supervised approach to define \"creditworthiness\" if labeled data becomes available.\n",
    "\n",
    "Explainable AI (XAI): Implement techniques like SHAP or LIME to provide more granular explanations for individual wallet scores, beyond just feature importance.\n",
    "\n",
    "Temporal Validation: Evaluate the model's performance on future data to ensure its robustness over time.\n",
    "\n",
    "Risk Categorization: Instead of just a score, categorize wallets into risk buckets (e.g., Low Risk, Medium Risk, High Risk)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59aa4485-5102-4709-afcb-7685187dfa93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All necessary libraries imported successfully.\n",
      "Loading data from user-transactions.json...\n",
      "Data loaded successfully. Total records: 100000\n",
      "First 5 rows of data:\n",
      "                                    _id  \\\n",
      "0  {'$oid': '681d38fed63812d4655f571a'}   \n",
      "1  {'$oid': '681aa70dd6df53021cc6f3c0'}   \n",
      "2  {'$oid': '681d04c2d63812d4654c733e'}   \n",
      "3  {'$oid': '681d133bd63812d46551b6ef'}   \n",
      "4  {'$oid': '681899e4ba49fc91cf2f4454'}   \n",
      "\n",
      "                                   userWallet  network protocol  \\\n",
      "0  0x00000000001accfa9cef68cf5371a23025b6d4b6  polygon  aave_v2   \n",
      "1  0x000000000051d07a4fb3bd10121a343d85818da6  polygon  aave_v2   \n",
      "2  0x000000000096026fb41fc39f9875d164bd82e2dc  polygon  aave_v2   \n",
      "3  0x000000000096026fb41fc39f9875d164bd82e2dc  polygon  aave_v2   \n",
      "4  0x0000000000e189dd664b9ab08a33c4839953852c  polygon  aave_v2   \n",
      "\n",
      "                                              txHash  \\\n",
      "0  0x695c69acf608fbf5d38e48ca5535e118cc213a89e3d6...   \n",
      "1  0xe6fc162c86b2928b0ba9b82bda672763665152b9de9d...   \n",
      "2  0xe2d7eb815c89331a734ed6f204a06c385a1b39040baa...   \n",
      "3  0x0d63a2eacd82b82f868db825ea7385e6bd8d046ee729...   \n",
      "4  0x590eabb812c5006a6f4766f44e6e9d3ad0b5b563de69...   \n",
      "\n",
      "                                               logId           timestamp  \\\n",
      "0  0x695c69acf608fbf5d38e48ca5535e118cc213a89e3d6... 2021-08-17 05:29:26   \n",
      "1  0xe6fc162c86b2928b0ba9b82bda672763665152b9de9d... 2021-05-20 15:36:53   \n",
      "2  0xe2d7eb815c89331a734ed6f204a06c385a1b39040baa... 2021-07-24 09:28:33   \n",
      "3  0x0d63a2eacd82b82f868db825ea7385e6bd8d046ee729... 2021-07-31 23:15:18   \n",
      "4  0x590eabb812c5006a6f4766f44e6e9d3ad0b5b563de69... 2021-04-19 15:25:07   \n",
      "\n",
      "   blockNumber            action  \\\n",
      "0   1629178166           deposit   \n",
      "1   1621525013           deposit   \n",
      "2   1627118913           deposit   \n",
      "3   1627773318           deposit   \n",
      "4   1618845907  redeemunderlying   \n",
      "\n",
      "                                          actionData  __v  \\\n",
      "0  {'type': 'Deposit', 'amount': '2000000000', 'a...    0   \n",
      "1  {'type': 'Deposit', 'amount': '145000000000000...    0   \n",
      "2  {'type': 'Deposit', 'amount': '100000000000000...    0   \n",
      "3  {'type': 'Deposit', 'amount': '400000000000000...    0   \n",
      "4  {'type': 'RedeemUnderlying', 'amount': '501548...    0   \n",
      "\n",
      "                               createdAt  \\\n",
      "0  {'$date': '2025-05-08T23:06:39.465Z'}   \n",
      "1  {'$date': '2025-05-07T00:19:26.159Z'}   \n",
      "2  {'$date': '2025-05-08T19:23:47.877Z'}   \n",
      "3  {'$date': '2025-05-08T20:25:33.141Z'}   \n",
      "4  {'$date': '2025-05-05T10:58:45.934Z'}   \n",
      "\n",
      "                               updatedAt  \n",
      "0  {'$date': '2025-05-08T23:06:39.465Z'}  \n",
      "1  {'$date': '2025-05-07T00:19:26.159Z'}  \n",
      "2  {'$date': '2025-05-08T19:23:47.877Z'}  \n",
      "3  {'$date': '2025-05-08T20:25:33.141Z'}  \n",
      "4  {'$date': '2025-05-05T10:58:45.934Z'}  \n",
      "\n",
      "Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 13 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   _id          100000 non-null  object        \n",
      " 1   userWallet   100000 non-null  object        \n",
      " 2   network      100000 non-null  object        \n",
      " 3   protocol     100000 non-null  object        \n",
      " 4   txHash       100000 non-null  object        \n",
      " 5   logId        100000 non-null  object        \n",
      " 6   timestamp    100000 non-null  datetime64[ns]\n",
      " 7   blockNumber  100000 non-null  int64         \n",
      " 8   action       100000 non-null  object        \n",
      " 9   actionData   100000 non-null  object        \n",
      " 10  __v          100000 non-null  int64         \n",
      " 11  createdAt    100000 non-null  object        \n",
      " 12  updatedAt    100000 non-null  object        \n",
      "dtypes: datetime64[ns](1), int64(2), object(10)\n",
      "memory usage: 9.9+ MB\n",
      "\n",
      "Engineering features from transaction data...\n",
      "Extracted 'amount' from 'actionData' and converted to numeric 'value_numeric'.\n",
      "Features engineered successfully. First 5 rows of features:\n",
      "   deposit_count  borrow_count  repay_count  redeem_count  liquidation_count  \\\n",
      "0              0             0            0             0                  0   \n",
      "1              0             0            0             0                  0   \n",
      "2              0             0            0             0                  0   \n",
      "3              0             0            0             0                  0   \n",
      "4              0             0            0             0                  0   \n",
      "\n",
      "   total_value_deposited  total_value_borrowed  total_value_repaid  \\\n",
      "0                    0.0                   0.0                 0.0   \n",
      "1                    0.0                   0.0                 0.0   \n",
      "2                    0.0                   0.0                 0.0   \n",
      "3                    0.0                   0.0                 0.0   \n",
      "4                    0.0                   0.0                 0.0   \n",
      "\n",
      "   total_value_redeemed  total_value_liquidated  account_age_days  \\\n",
      "0                   0.0                     0.0                 0   \n",
      "1                   0.0                     0.0                 0   \n",
      "2                   0.0                     0.0                 7   \n",
      "3                   0.0                     0.0               129   \n",
      "4                   0.0                     0.0               132   \n",
      "\n",
      "   borrow_repay_ratio  net_borrow_exposure  liquidation_rate  \n",
      "0                 0.0                  0.0               0.0  \n",
      "1                 0.0                  0.0               0.0  \n",
      "2                 0.0                  0.0               0.0  \n",
      "3                 0.0                  0.0               0.0  \n",
      "4                 0.0                  0.0               0.0  \n",
      "\n",
      "Total wallets processed: 3497\n",
      "\n",
      "Assigning heuristic credit scores (0-1000) for model training...\n",
      "Heuristic scores assigned. First 5 scores:\n",
      "0    500\n",
      "1    500\n",
      "2    502\n",
      "3    542\n",
      "4    543\n",
      "dtype: int64\n",
      "Score distribution (min, max, mean): 500, 550, 507.05\n",
      "\n",
      "Starting model training and evaluation...\n",
      "Features scaled.\n",
      "Data split into training (2797 samples) and testing (700 samples).\n",
      "Training Gradient Boosting Regressor model...\n",
      "Model training complete.\n",
      "Model Performance on Test Set:\n",
      "  Root Mean Squared Error (RMSE): 0.04\n",
      "  R-squared (R2) Score: 1.00\n",
      "An R2 score closer to 1 indicates a better fit; RMSE indicates average prediction error.\n",
      "\n",
      "Model and Scaler saved as 'model.joblib' and 'scaler.joblib' in the current directory.\n",
      "\n",
      "First 10 predicted credit scores for all wallets:\n",
      "                                       wallet  credit_score\n",
      "0  0x00000000001accfa9cef68cf5371a23025b6d4b6           500\n",
      "1  0x000000000051d07a4fb3bd10121a343d85818da6           500\n",
      "2  0x000000000096026fb41fc39f9875d164bd82e2dc           502\n",
      "3  0x0000000000e189dd664b9ab08a33c4839953852c           542\n",
      "4  0x0000000002032370b971dabd36d72f3e5a7bf1ee           543\n",
      "5  0x000000000a38444e0a6e37d3b630d7e855a7cb13           513\n",
      "6  0x000000003853fcedcd0355fec98ca3192833f00b           502\n",
      "7  0x000000003ce0cf2c037493b1dc087204bd7f713e           540\n",
      "8  0x000000007858e6f2668e1e06111cfa24403a5466           500\n",
      "9  0x00000001a0f57e850c9db68b4a9bc34677437c5c           500\n",
      "Predicted score distribution (min, max, mean): 500, 550, 507.06\n",
      "\n",
      "--- Running One-Step Scoring Script for 'user-transactions.json' ---\n",
      "Loading data from user-transactions.json...\n",
      "Data loaded successfully. Total records: 100000\n",
      "First 5 rows of data:\n",
      "                                    _id  \\\n",
      "0  {'$oid': '681d38fed63812d4655f571a'}   \n",
      "1  {'$oid': '681aa70dd6df53021cc6f3c0'}   \n",
      "2  {'$oid': '681d04c2d63812d4654c733e'}   \n",
      "3  {'$oid': '681d133bd63812d46551b6ef'}   \n",
      "4  {'$oid': '681899e4ba49fc91cf2f4454'}   \n",
      "\n",
      "                                   userWallet  network protocol  \\\n",
      "0  0x00000000001accfa9cef68cf5371a23025b6d4b6  polygon  aave_v2   \n",
      "1  0x000000000051d07a4fb3bd10121a343d85818da6  polygon  aave_v2   \n",
      "2  0x000000000096026fb41fc39f9875d164bd82e2dc  polygon  aave_v2   \n",
      "3  0x000000000096026fb41fc39f9875d164bd82e2dc  polygon  aave_v2   \n",
      "4  0x0000000000e189dd664b9ab08a33c4839953852c  polygon  aave_v2   \n",
      "\n",
      "                                              txHash  \\\n",
      "0  0x695c69acf608fbf5d38e48ca5535e118cc213a89e3d6...   \n",
      "1  0xe6fc162c86b2928b0ba9b82bda672763665152b9de9d...   \n",
      "2  0xe2d7eb815c89331a734ed6f204a06c385a1b39040baa...   \n",
      "3  0x0d63a2eacd82b82f868db825ea7385e6bd8d046ee729...   \n",
      "4  0x590eabb812c5006a6f4766f44e6e9d3ad0b5b563de69...   \n",
      "\n",
      "                                               logId           timestamp  \\\n",
      "0  0x695c69acf608fbf5d38e48ca5535e118cc213a89e3d6... 2021-08-17 05:29:26   \n",
      "1  0xe6fc162c86b2928b0ba9b82bda672763665152b9de9d... 2021-05-20 15:36:53   \n",
      "2  0xe2d7eb815c89331a734ed6f204a06c385a1b39040baa... 2021-07-24 09:28:33   \n",
      "3  0x0d63a2eacd82b82f868db825ea7385e6bd8d046ee729... 2021-07-31 23:15:18   \n",
      "4  0x590eabb812c5006a6f4766f44e6e9d3ad0b5b563de69... 2021-04-19 15:25:07   \n",
      "\n",
      "   blockNumber            action  \\\n",
      "0   1629178166           deposit   \n",
      "1   1621525013           deposit   \n",
      "2   1627118913           deposit   \n",
      "3   1627773318           deposit   \n",
      "4   1618845907  redeemunderlying   \n",
      "\n",
      "                                          actionData  __v  \\\n",
      "0  {'type': 'Deposit', 'amount': '2000000000', 'a...    0   \n",
      "1  {'type': 'Deposit', 'amount': '145000000000000...    0   \n",
      "2  {'type': 'Deposit', 'amount': '100000000000000...    0   \n",
      "3  {'type': 'Deposit', 'amount': '400000000000000...    0   \n",
      "4  {'type': 'RedeemUnderlying', 'amount': '501548...    0   \n",
      "\n",
      "                               createdAt  \\\n",
      "0  {'$date': '2025-05-08T23:06:39.465Z'}   \n",
      "1  {'$date': '2025-05-07T00:19:26.159Z'}   \n",
      "2  {'$date': '2025-05-08T19:23:47.877Z'}   \n",
      "3  {'$date': '2025-05-08T20:25:33.141Z'}   \n",
      "4  {'$date': '2025-05-05T10:58:45.934Z'}   \n",
      "\n",
      "                               updatedAt  \n",
      "0  {'$date': '2025-05-08T23:06:39.465Z'}  \n",
      "1  {'$date': '2025-05-07T00:19:26.159Z'}  \n",
      "2  {'$date': '2025-05-08T19:23:47.877Z'}  \n",
      "3  {'$date': '2025-05-08T20:25:33.141Z'}  \n",
      "4  {'$date': '2025-05-05T10:58:45.934Z'}  \n",
      "\n",
      "Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 13 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   _id          100000 non-null  object        \n",
      " 1   userWallet   100000 non-null  object        \n",
      " 2   network      100000 non-null  object        \n",
      " 3   protocol     100000 non-null  object        \n",
      " 4   txHash       100000 non-null  object        \n",
      " 5   logId        100000 non-null  object        \n",
      " 6   timestamp    100000 non-null  datetime64[ns]\n",
      " 7   blockNumber  100000 non-null  int64         \n",
      " 8   action       100000 non-null  object        \n",
      " 9   actionData   100000 non-null  object        \n",
      " 10  __v          100000 non-null  int64         \n",
      " 11  createdAt    100000 non-null  object        \n",
      " 12  updatedAt    100000 non-null  object        \n",
      "dtypes: datetime64[ns](1), int64(2), object(10)\n",
      "memory usage: 9.9+ MB\n",
      "\n",
      "Engineering features from transaction data...\n",
      "Extracted 'amount' from 'actionData' and converted to numeric 'value_numeric'.\n",
      "Features engineered successfully. First 5 rows of features:\n",
      "   deposit_count  borrow_count  repay_count  redeem_count  liquidation_count  \\\n",
      "0              0             0            0             0                  0   \n",
      "1              0             0            0             0                  0   \n",
      "2              0             0            0             0                  0   \n",
      "3              0             0            0             0                  0   \n",
      "4              0             0            0             0                  0   \n",
      "\n",
      "   total_value_deposited  total_value_borrowed  total_value_repaid  \\\n",
      "0                    0.0                   0.0                 0.0   \n",
      "1                    0.0                   0.0                 0.0   \n",
      "2                    0.0                   0.0                 0.0   \n",
      "3                    0.0                   0.0                 0.0   \n",
      "4                    0.0                   0.0                 0.0   \n",
      "\n",
      "   total_value_redeemed  total_value_liquidated  account_age_days  \\\n",
      "0                   0.0                     0.0                 0   \n",
      "1                   0.0                     0.0                 0   \n",
      "2                   0.0                     0.0                 7   \n",
      "3                   0.0                     0.0               129   \n",
      "4                   0.0                     0.0               132   \n",
      "\n",
      "   borrow_repay_ratio  net_borrow_exposure  liquidation_rate  \n",
      "0                 0.0                  0.0               0.0  \n",
      "1                 0.0                  0.0               0.0  \n",
      "2                 0.0                  0.0               0.0  \n",
      "3                 0.0                  0.0               0.0  \n",
      "4                 0.0                  0.0               0.0  \n",
      "\n",
      "Total wallets processed: 3497\n",
      "Loading pre-trained model and scaler...\n",
      "Model and Scaler loaded successfully.\n",
      "New features scaled using the pre-trained scaler.\n",
      "Predicting scores for new wallets...\n",
      "Scores generated and saved to 'wallet_credit_scores_generated.json' in the current directory.\n",
      "\n",
      "First 10 generated credit scores:\n",
      "                                       wallet  credit_score\n",
      "0  0x00000000001accfa9cef68cf5371a23025b6d4b6           500\n",
      "1  0x000000000051d07a4fb3bd10121a343d85818da6           500\n",
      "2  0x000000000096026fb41fc39f9875d164bd82e2dc           502\n",
      "3  0x0000000000e189dd664b9ab08a33c4839953852c           542\n",
      "4  0x0000000002032370b971dabd36d72f3e5a7bf1ee           543\n",
      "5  0x000000000a38444e0a6e37d3b630d7e855a7cb13           513\n",
      "6  0x000000003853fcedcd0355fec98ca3192833f00b           502\n",
      "7  0x000000003ce0cf2c037493b1dc087204bd7f713e           540\n",
      "8  0x000000007858e6f2668e1e06111cfa24403a5466           500\n",
      "9  0x00000001a0f57e850c9db68b4a9bc34677437c5c           500\n"
     ]
    }
   ],
   "source": [
    "# ALL NECESSARY LIBRARIES ----\n",
    "\n",
    "import json\n",
    "import pandas as pd                 # For analysis part for finding insigths from data\n",
    "import numpy as np                  # For mathematical evaluations\n",
    "import re                          # For regular expressions, if needed for complex parsing\n",
    "from sklearn.model_selection import train_test_split     # For splitting data into two parts -- FOR TRAINING(75%) & FOR TESTING(25%)\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler         #Feature Scaling\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib                       # For saving/loading the trained model and scaler\n",
    "# Suppress warnings for cleaner output in notebook\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"All necessary libraries imported successfully.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# DATA LOADING ----\n",
    "\n",
    "\"\"\"\n",
    "    Loads transaction data from a JSON file into a pandas DataFrame.\n",
    "    Converts 'timestamp' to datetime objects.\n",
    "\n",
    "    Args:\n",
    "        json_file_path (str): The path to the user-transactions.json file.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing the transaction data.\n",
    "\"\"\"\n",
    "\n",
    "def load_data(json_file_path):\n",
    "    print(f\"Loading data from {json_file_path}...\")\n",
    "    try:\n",
    "        with open(json_file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        df = pd.DataFrame(data)\n",
    "        # Convert 'timestamp' from Unix timestamp (seconds) to datetime\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "        print(f\"Data loaded successfully. Total records: {len(df)}\")\n",
    "        print(\"First 5 rows of data:\")\n",
    "        print(df.head())\n",
    "        print(\"\\nData Info:\")\n",
    "        df.info()\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{json_file_path}' was not found.\")\n",
    "        print(\"Please ensure you have downloaded 'user-transactions.json' and placed it in the same directory as this notebook.\")\n",
    "        return pd.DataFrame() # Return empty DataFrame on error\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while loading data: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Execute Data Loading ---\n",
    "transactions_df = load_data('user-transactions.json')\n",
    "\n",
    "# Check if data loaded successfully before proceeding\n",
    "if transactions_df.empty:\n",
    "    raise SystemExit(\"Data loading failed. Exiting notebook execution.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# FEATURE SCALING ----\n",
    "\n",
    "\"\"\"\n",
    "    Engineers relevant features from the raw transaction DataFrame for credit scoring.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame of Aave V2 transactions.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - pd.DataFrame: DataFrame of engineered features.\n",
    "            - pd.Series: Series of wallet addresses corresponding to the features.\n",
    "\"\"\"\n",
    "\n",
    "def engineer_features(df):\n",
    "    \"\"\"\n",
    "    Engineers relevant features from the raw transaction DataFrame for credit scoring.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame of Aave V2 transactions.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - pd.DataFrame: DataFrame of engineered features.\n",
    "            - pd.Series: Series of wallet addresses corresponding to the features.\n",
    "    \"\"\"\n",
    "    print(\"\\nEngineering features from transaction data...\")\n",
    "\n",
    "    # --- CRITICAL CHANGE HERE: Extract 'amount' from 'actionData' ---\n",
    "    # We need to safely extract the 'amount' key from the dictionary in 'actionData'.\n",
    "    # Use .apply(lambda x: x.get('amount', '0')) to handle cases where 'amount' might be missing\n",
    "    # and default to '0' (as a string) before converting to numeric.\n",
    "    df['value_numeric'] = df['actionData'].apply(lambda x: x.get('amount', '0'))\n",
    "    df['value_numeric'] = pd.to_numeric(df['value_numeric'], errors='coerce').fillna(0)\n",
    "    print(\"Extracted 'amount' from 'actionData' and converted to numeric 'value_numeric'.\")\n",
    "\n",
    "\n",
    "    # Group by wallet to create aggregated features\n",
    "    # Grouping by 'userWallet' as per your data's column name\n",
    "    wallet_features = df.groupby('userWallet').agg(\n",
    "        # Transaction Counts for each action type\n",
    "        total_transactions=('txHash', 'count'), # Using 'txHash' as the unique transaction identifier\n",
    "        # Using exact action names as found in your 'actionData' output (case-sensitive)\n",
    "        deposit_count=('action', lambda x: (x == 'Deposit').sum()),\n",
    "        borrow_count=('action', lambda x: (x == 'Borrow').sum()),\n",
    "        repay_count=('action', lambda x: (x == 'Repay').sum()),\n",
    "        redeem_count=('action', lambda x: (x == 'RedeemUnderlying').sum()),\n",
    "        liquidation_count=('action', lambda x: (x == 'LiquidationCall').sum()),\n",
    "\n",
    "        # Sum of values for each action type\n",
    "        # These lambda functions correctly use df.loc[x.index, 'action'] to filter based on the original DataFrame's action column\n",
    "        total_value_deposited=('value_numeric', lambda x: x[df.loc[x.index, 'action'] == 'Deposit'].sum()),\n",
    "        total_value_borrowed=('value_numeric', lambda x: x[df.loc[x.index, 'action'] == 'Borrow'].sum()),\n",
    "        total_value_repaid=('value_numeric', lambda x: x[df.loc[x.index, 'action'] == 'Repay'].sum()),\n",
    "        total_value_redeemed=('value_numeric', lambda x: x[df.loc[x.index, 'action'] == 'RedeemUnderlying'].sum()),\n",
    "        total_value_liquidated=('value_numeric', lambda x: x[df.loc[x.index, 'action'] == 'LiquidationCall'].sum()),\n",
    "\n",
    "        # Time-based Features: First and last transaction timestamps\n",
    "        first_transaction_time=('timestamp', 'min'),\n",
    "        last_transaction_time=('timestamp', 'max'),\n",
    "    ).reset_index()\n",
    "\n",
    "    # Calculate derived features\n",
    "    # Account age in days: Difference between last and first transaction\n",
    "    wallet_features['account_age_days'] = (wallet_features['last_transaction_time'] - wallet_features['first_transaction_time']).dt.days\n",
    "    # Handle cases where account age might be 0 (single transaction) or NaN\n",
    "    wallet_features['account_age_days'] = wallet_features['account_age_days'].fillna(0)\n",
    "\n",
    "\n",
    "    # Borrow-to-Repay Ratio: Higher is generally better for creditworthiness\n",
    "    # Add a small epsilon (1e-9) to the denominator to prevent division by zero for wallets with no borrows.\n",
    "    wallet_features['borrow_repay_ratio'] = wallet_features['total_value_repaid'] / (wallet_features['total_value_borrowed'] + 1e-9)\n",
    "    # Replace infinite values (if total_value_borrowed was 0 and repaid was >0) with a high value or 0\n",
    "    wallet_features['borrow_repay_ratio'] = wallet_features['borrow_repay_ratio'].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "\n",
    "\n",
    "    # Net Borrow Exposure: Total borrowed minus total repaid. Positive means outstanding debt.\n",
    "    wallet_features['net_borrow_exposure'] = wallet_features['total_value_borrowed'] - wallet_features['total_value_repaid']\n",
    "\n",
    "    # Liquidation Rate: Frequency of liquidations relative to total activity\n",
    "    wallet_features['liquidation_rate'] = wallet_features['liquidation_count'] / (wallet_features['total_transactions'] + 1e-9)\n",
    "    wallet_features['liquidation_rate'] = wallet_features['liquidation_rate'].fillna(0) # Fill NaN if total_transactions is 0\n",
    "\n",
    "\n",
    "    # Define the list of features that will be used by the ML model\n",
    "    features_for_model = [\n",
    "        'deposit_count', 'borrow_count', 'repay_count', 'redeem_count', 'liquidation_count',\n",
    "        'total_value_deposited', 'total_value_borrowed', 'total_value_repaid',\n",
    "        'total_value_redeemed', 'total_value_liquidated',\n",
    "        'account_age_days', 'borrow_repay_ratio', 'net_borrow_exposure', 'liquidation_rate'\n",
    "    ]\n",
    "\n",
    "    print(\"Features engineered successfully. First 5 rows of features:\")\n",
    "    print(wallet_features[features_for_model].head())\n",
    "    print(f\"\\nTotal wallets processed: {len(wallet_features)}\")\n",
    "\n",
    "    return wallet_features[features_for_model], wallet_features['userWallet'] # Returning 'userWallet' as the wallet identifier\n",
    "\n",
    "# --- Execute Feature Engineering ---\n",
    "features_df, wallets = engineer_features(transactions_df)\n",
    "\n",
    "# Check if features were engineered successfully\n",
    "if features_df.empty:\n",
    "    raise SystemExit(\"Feature engineering failed. Exiting notebook execution.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# HEAURISTIC TARGET SCORE ----\n",
    "\n",
    "\"\"\"\n",
    "    Assigns a heuristic credit score (0-1000) to each wallet based on engineered features.\n",
    "    This score serves as a proxy target variable for the supervised learning model.\n",
    "    The logic here defines what 'good' and 'bad' behavior means in our context.\n",
    "\n",
    "    Args:\n",
    "        features_df (pd.DataFrame): DataFrame of engineered features.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: A Series of heuristic credit scores for each wallet.\n",
    "\"\"\"\n",
    "\n",
    "def assign_heuristic_score(features_df):\n",
    "    \"\"\"\n",
    "    Assigns a heuristic credit score (0-1000) to each wallet based on engineered features.\n",
    "    This score serves as a proxy target variable for the supervised learning model.\n",
    "    The logic here defines what 'good' and 'bad' behavior means in our context.\n",
    "\n",
    "    Args:\n",
    "        features_df (pd.DataFrame): DataFrame of engineered features.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: A Series of heuristic credit scores for each wallet.\n",
    "    \"\"\"\n",
    "    print(\"\\nAssigning heuristic credit scores (0-1000) for model training...\")\n",
    "\n",
    "    # Initialize all scores to a base value (e.g., 500)\n",
    "    scores = pd.Series(np.full(len(features_df), 500), index=features_df.index)\n",
    "\n",
    "    # --- Reward Positive Behaviors ---\n",
    "    # 1. Reward good repayment behavior (higher borrow_repay_ratio)\n",
    "    # Max 300 points for a very good ratio. Using log scale to dampen extreme values.\n",
    "    scores += (np.log1p(features_df['borrow_repay_ratio']) * 50).clip(0, 300)\n",
    "\n",
    "    # 2. Reward significant total value repaid (indicates active, responsible usage)\n",
    "    # Normalized by max total repaid value to get a score between 0-100\n",
    "    if features_df['total_value_repaid'].max() > 0:\n",
    "        scores += (features_df['total_value_repaid'] / features_df['total_value_repaid'].max() * 100).fillna(0).clip(0, 100)\n",
    "\n",
    "    # 3. Reward account age (longer active accounts might be more reliable)\n",
    "    # Normalized by max account age to get a score between 0-50\n",
    "    if features_df['account_age_days'].max() > 0:\n",
    "        scores += (features_df['account_age_days'] / features_df['account_age_days'].max() * 50).fillna(0).clip(0, 50)\n",
    "\n",
    "\n",
    "    # --- Penalize Negative Behaviors ---\n",
    "    # 1. Penalize liquidations heavily (strongest negative signal)\n",
    "    # Each liquidation reduces score significantly. Max reduction 500 points.\n",
    "    scores -= (features_df['liquidation_count'] * 100).clip(0, 500)\n",
    "\n",
    "    # 2. Penalize high liquidation rate\n",
    "    # Higher rate means more frequent failures. Max reduction 200 points.\n",
    "    scores -= (features_df['liquidation_rate'] * 200).clip(0, 200)\n",
    "\n",
    "    # 3. Penalize significant net borrow exposure (unrepaid debt)\n",
    "    # Normalized by max net exposure. Max reduction 150 points.\n",
    "    if features_df['net_borrow_exposure'].max() > 0:\n",
    "        scores -= (features_df['net_borrow_exposure'] / features_df['net_borrow_exposure'].max() * 150).fillna(0).clip(0, 150)\n",
    "\n",
    "\n",
    "    # Clamp scores between 0 and 1000 to ensure they stay within the desired range\n",
    "    scores = scores.clip(0, 1000).round(0).astype(int)\n",
    "\n",
    "    print(\"Heuristic scores assigned. First 5 scores:\")\n",
    "    print(scores.head())\n",
    "    print(f\"Score distribution (min, max, mean): {scores.min()}, {scores.max()}, {scores.mean():.2f}\")\n",
    "\n",
    "    return scores\n",
    "\n",
    "# --- Execute Heuristic Score Assignment ---\n",
    "heuristic_scores = assign_heuristic_score(features_df)\n",
    "\n",
    "\n",
    "\n",
    "# MODEL TRINING AND SAVING ----\n",
    "\"\"\"\n",
    "    Trains a Gradient Boosting Regressor model, evaluates it, and saves the\n",
    "    trained model and the StandardScaler for future use.\n",
    "\n",
    "    Args:\n",
    "        features_df (pd.DataFrame): DataFrame of engineered features.\n",
    "        target_scores (pd.Series): Series of heuristic credit scores (target variable).\n",
    "        wallets (pd.Series): Series of wallet addresses.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing wallet addresses and their predicted credit scores.\n",
    "\"\"\"\n",
    "\n",
    "def train_and_save_model(features_df, target_scores, wallets):\n",
    "    print(\"\\nStarting model training and evaluation...\")\n",
    "\n",
    "    # 1. Scale Features: Standardize features to have mean 0 and variance 1\n",
    "    # This is important for many ML models, including Gradient Boosting,\n",
    "    # though it's less sensitive than linear models or neural networks.\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(features_df)\n",
    "    print(\"Features scaled.\")\n",
    "\n",
    "    # 2. Split Data: Divide data into training and testing sets\n",
    "    # 80% for training, 20% for testing to evaluate model performance.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, target_scores, test_size=0.2, random_state=42         # fixed random_state for reproducibility\n",
    "    )\n",
    "    print(f\"Data split into training ({len(X_train)} samples) and testing ({len(X_test)} samples).\")\n",
    "\n",
    "    # 3. Initialize and Train Model: Gradient Boosting Regressor\n",
    "    # n_estimators: number of boosting stages\n",
    "    # learning_rate: shrinks the contribution of each tree\n",
    "    # max_depth: limits the number of nodes in the tree\n",
    "    model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "    print(\"Training Gradient Boosting Regressor model...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"Model training complete.\")\n",
    "\n",
    "    # 4. Evaluate Model Performance on the test set\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "    r2 = r2_score(y_test, y_pred_test)\n",
    "    print(f\"Model Performance on Test Set:\")\n",
    "    print(f\"  Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "    print(f\"  R-squared (R2) Score: {r2:.2f}\")\n",
    "    print(\"An R2 score closer to 1 indicates a better fit; RMSE indicates average prediction error.\")\n",
    "\n",
    "\n",
    "    # 5. Predict Scores for ALL Wallets (using the full dataset)\n",
    "    # Transform the entire feature set using the *fitted* scaler\n",
    "    all_wallet_scores_predicted = model.predict(scaler.transform(features_df))\n",
    "\n",
    "    # Clamp scores to the 0-1000 range and round to nearest integer\n",
    "    final_scores_df = pd.DataFrame({\n",
    "        'wallet': wallets,\n",
    "        'credit_score': all_wallet_scores_predicted.clip(0, 1000).round(0).astype(int)\n",
    "    })\n",
    "    # 6. Save the trained model and scaler for the one-step script\n",
    "    # This allows the scoring script to use the exact same transformation and prediction logic\n",
    "    joblib.dump(scaler, 'scaler.joblib')\n",
    "    joblib.dump(model, 'model.joblib')\n",
    "    print(\"\\nModel and Scaler saved as 'model.joblib' and 'scaler.joblib' in the current directory.\")\n",
    "\n",
    "    print(\"\\nFirst 10 predicted credit scores for all wallets:\")\n",
    "    print(final_scores_df.head(10))\n",
    "    print(f\"Predicted score distribution (min, max, mean): {final_scores_df['credit_score'].min()}, {final_scores_df['credit_score'].max()}, {final_scores_df['credit_score'].mean():.2f}\")\n",
    "\n",
    "    return final_scores_df\n",
    "\n",
    "# --- Execute Model Training and Saving ---\n",
    "final_predicted_scores_df = train_and_save_model(features_df, heuristic_scores, wallets)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ONE STEP SCORING SCRIPT ----\n",
    "\n",
    "\"\"\"\n",
    "    Generates wallet credit scores from a new JSON transaction file using a pre-trained model.\n",
    "\n",
    "    Args:\n",
    "        json_file_path (str): Path to the input JSON file with transaction data.\n",
    "        model_path (str): Path to the saved machine learning model (.joblib).\n",
    "        scaler_path (str): Path to the saved StandardScaler (.joblib).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing wallet addresses and their predicted credit scores.\n",
    "\"\"\"\n",
    "\n",
    "# This section simulates the 'one-step script' (score_wallets.py)\n",
    "# It demonstrates how you would load the saved model and scaler\n",
    "# to predict scores for a new (or the same) dataset.\n",
    "\n",
    "def generate_wallet_scores_from_file(json_file_path, model_path='model.joblib', scaler_path='scaler.joblib'):\n",
    "    print(f\"\\n--- Running One-Step Scoring Script for '{json_file_path}' ---\")\n",
    "\n",
    "    # 1. Load Data\n",
    "    transactions_df_new = load_data(json_file_path)\n",
    "    if transactions_df_new.empty:\n",
    "        print(\"Skipping score generation due to data loading error.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # 2. Engineer Features (using the same logic as training)\n",
    "    features_df_new, wallets_new = engineer_features(transactions_df_new)\n",
    "    if features_df_new.empty:\n",
    "        print(\"Skipping score generation due to feature engineering error.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # 3. Load Pre-trained Model and Scaler\n",
    "    print(\"Loading pre-trained model and scaler...\")\n",
    "    try:\n",
    "        scaler = joblib.load(scaler_path)\n",
    "        model = joblib.load(model_path)\n",
    "        print(\"Model and Scaler loaded successfully.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Model or Scaler files not found at '{model_path}' or '{scaler_path}'.\")\n",
    "        print(\"Please ensure you have run the 'Model Training and Saving' cell above to create these files.\")\n",
    "        return pd.DataFrame()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while loading model/scaler: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # 4. Scale New Features (using the loaded scaler)\n",
    "    # It's crucial to use the *same* scaler fitted on the training data.\n",
    "    X_scaled_new = scaler.transform(features_df_new)\n",
    "    print(\"New features scaled using the pre-trained scaler.\")\n",
    "\n",
    "    # 5. Predict Scores\n",
    "    print(\"Predicting scores for new wallets...\")\n",
    "    predicted_scores_new = model.predict(X_scaled_new)\n",
    "\n",
    "    # 6. Clamp scores to 0-1000 range and format\n",
    "    final_scores_df_new = pd.DataFrame({\n",
    "        'wallet': wallets_new,\n",
    "        'credit_score': predicted_scores_new.clip(0, 1000).round(0).astype(int)\n",
    "    })\n",
    "\n",
    "    # 7. Output Results\n",
    "    output_filename = 'wallet_credit_scores_generated.json'\n",
    "    final_scores_df_new.to_json(output_filename, orient='records', indent=4)\n",
    "    print(f\"Scores generated and saved to '{output_filename}' in the current directory.\")\n",
    "    print(\"\\nFirst 10 generated credit scores:\")\n",
    "    print(final_scores_df_new.head(10))\n",
    "\n",
    "    return final_scores_df_new\n",
    "\n",
    "# --- Execute the simulated one-step script ---\n",
    "# This will use the 'user-transactions.json' file again,\n",
    "# but it demonstrates the process of loading the saved model.\n",
    "generated_scores_from_script = generate_wallet_scores_from_file('user-transactions.json')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
